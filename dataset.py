import torch
import numpy as np
from torch.utils.data import Dataset
import os
import glob


def load_face_data(data):
    Heat_data_sample = np.load('./%s-npy/Heat_data_sample.npy' % data, allow_pickle=True)
    Shape_sample = np.load('./%s-npy/shape_sample.npy' % data, allow_pickle=True)
    landmark_position_select_all = np.load('./%s-npy/landmark_position_select_all.npy' % data, allow_pickle=True)
    if data == 'BU-3DFE' or data == 'FaceScape' or data == 'FRGC':
        return Shape_sample, landmark_position_select_all, Heat_data_sample


class FaceLandmarkData(Dataset):
    def __init__(self, data_dir, partition='trainval', num_points=2048):
        self.data_dir = data_dir
        self.partition = partition
        self.num_points = num_points
        self.indices = []  # Initialize indices as empty list
        
        print(f"Loading data from: {data_dir}")
        
        # Get all shape files
        self.shape_files = sorted(glob.glob(os.path.join(data_dir, 'shapes', '*_FC_A.npy')))
        print(f"Found {len(self.shape_files)} shape files")
        
        # Get corresponding landmark files by replacing FC_A with FA_A
        self.landmark_files = []
        for shape_file in self.shape_files:
            landmark_file = shape_file.replace('shapes', 'landmarks').replace('FC_A', 'FA_A')
            if os.path.exists(landmark_file):
                self.landmark_files.append(landmark_file)
            else:
                print(f"Warning: Landmark file not found for {shape_file}")
        
        # Remove shape files that don't have corresponding landmark files
        self.shape_files = [f for f in self.shape_files if f.replace('shapes', 'landmarks').replace('FC_A', 'FA_A') in self.landmark_files]
        
        assert len(self.shape_files) == len(self.landmark_files), "Number of shape files and landmark files must match"
        print(f"Found {len(self.shape_files)} matching pairs of shape and landmark files")
        
        if len(self.shape_files) == 0:
            print("ERROR: No matching files found!")
            print(f"Shape files pattern: {os.path.join(data_dir, 'shapes', '*_FC_A.npy')}")
            print(f"Landmark files pattern: {os.path.join(data_dir, 'landmarks', '*_FA_A.npy')}")
            return
        
        # Split into train and val sets (80% train, 20% val)
        num_samples = len(self.shape_files)
        indices = np.random.permutation(num_samples)
        if partition == 'train':
            self.indices = indices[:int(0.8 * num_samples)]
        elif partition == 'val':
            self.indices = indices[int(0.8 * num_samples):]
        else:  # trainval
            self.indices = indices

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        shape_idx = self.indices[idx]
        
        # Load shape data
        shape_data = np.load(self.shape_files[shape_idx])
        points = shape_data[:, :3]  # xyz coordinates
        
        # Load landmark data
        landmark_data = np.load(self.landmark_files[shape_idx])
        landmarks = landmark_data[:, :3]  # xyz coordinates
        
        # Randomly sample points if needed
        if len(points) > self.num_points:
            choice = np.random.choice(len(points), self.num_points, replace=False)
            points = points[choice]
        
        # Convert to torch tensors
        points = torch.FloatTensor(points)
        landmarks = torch.FloatTensor(landmarks)
        
        return points, landmarks, None  # None for heatmap (will be generated by model)




